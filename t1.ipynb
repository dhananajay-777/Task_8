{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Natural Language Processing Task\n",
    "Task-1\n",
    "\tYou need to translate each word or sentence from English to Spanish, French and German \n",
    "\n",
    "Data Set : https://drive.google.com/file/d/1YMHJjblc8dDzUN1ry8BOCnAR4_TyKmXM/view?usp=sharing\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting googletransNote: you may need to restart the kernel to use updated packages.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  WARNING: The script chardetect.exe is installed in 'C:\\Users\\dhana\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.10_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python310\\Scripts' which is not on PATH.\n",
      "  Consider adding this directory to PATH or, if you prefer to suppress this warning, use --no-warn-script-location.\n",
      "  DEPRECATION: googletrans is being installed using the legacy 'setup.py install' method, because it does not have a 'pyproject.toml' and the 'wheel' package is not installed. pip 23.1 will enforce this behaviour change. A possible replacement is to enable the '--use-pep517' option. Discussion can be found at https://github.com/pypa/pip/issues/8559\n",
      "\n",
      "[notice] A new release of pip available: 22.3.1 -> 23.0\n",
      "[notice] To update, run: C:\\Users\\dhana\\AppData\\Local\\Microsoft\\WindowsApps\\PythonSoftwareFoundation.Python.3.10_qbz5n2kfra8p0\\python.exe -m pip install --upgrade pip\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "  Downloading googletrans-3.0.0.tar.gz (17 kB)\n",
      "  Preparing metadata (setup.py): started\n",
      "  Preparing metadata (setup.py): finished with status 'done'\n",
      "Collecting httpx==0.13.3\n",
      "  Downloading httpx-0.13.3-py3-none-any.whl (55 kB)\n",
      "     ---------------------------------------- 55.1/55.1 kB 2.8 MB/s eta 0:00:00\n",
      "Collecting chardet==3.*\n",
      "  Downloading chardet-3.0.4-py2.py3-none-any.whl (133 kB)\n",
      "     -------------------------------------- 133.4/133.4 kB 3.8 MB/s eta 0:00:00\n",
      "Collecting idna==2.*\n",
      "  Downloading idna-2.10-py2.py3-none-any.whl (58 kB)\n",
      "     ---------------------------------------- 58.8/58.8 kB 3.0 MB/s eta 0:00:00\n",
      "Collecting rfc3986<2,>=1.3\n",
      "  Downloading rfc3986-1.5.0-py2.py3-none-any.whl (31 kB)\n",
      "Collecting hstspreload\n",
      "  Downloading hstspreload-2023.1.1-py3-none-any.whl (1.5 MB)\n",
      "     ---------------------------------------- 1.5/1.5 MB 5.8 MB/s eta 0:00:00\n",
      "Collecting httpcore==0.9.*\n",
      "  Downloading httpcore-0.9.1-py3-none-any.whl (42 kB)\n",
      "     ---------------------------------------- 42.6/42.6 kB ? eta 0:00:00\n",
      "Collecting sniffio\n",
      "  Downloading sniffio-1.3.0-py3-none-any.whl (10 kB)\n",
      "Collecting certifi\n",
      "  Downloading certifi-2022.12.7-py3-none-any.whl (155 kB)\n",
      "     -------------------------------------- 155.3/155.3 kB 3.1 MB/s eta 0:00:00\n",
      "Collecting h11<0.10,>=0.8\n",
      "  Downloading h11-0.9.0-py2.py3-none-any.whl (53 kB)\n",
      "     ---------------------------------------- 53.6/53.6 kB 2.9 MB/s eta 0:00:00\n",
      "Collecting h2==3.*\n",
      "  Downloading h2-3.2.0-py2.py3-none-any.whl (65 kB)\n",
      "     ---------------------------------------- 65.0/65.0 kB 3.4 MB/s eta 0:00:00\n",
      "Collecting hpack<4,>=3.0\n",
      "  Downloading hpack-3.0.0-py2.py3-none-any.whl (38 kB)\n",
      "Collecting hyperframe<6,>=5.2.0\n",
      "  Downloading hyperframe-5.2.0-py2.py3-none-any.whl (12 kB)\n",
      "Installing collected packages: rfc3986, hyperframe, hpack, h11, chardet, sniffio, idna, hstspreload, h2, certifi, httpcore, httpx, googletrans\n",
      "  Running setup.py install for googletrans: started\n",
      "  Running setup.py install for googletrans: finished with status 'done'\n",
      "Successfully installed certifi-2022.12.7 chardet-3.0.4 googletrans-3.0.0 h11-0.9.0 h2-3.2.0 hpack-3.0.0 hstspreload-2023.1.1 httpcore-0.9.1 httpx-0.13.3 hyperframe-5.2.0 idna-2.10 rfc3986-1.5.0 sniffio-1.3.0\n"
     ]
    }
   ],
   "source": [
    "pip install googletrans"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Installing Deep translate as well "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting deep-translator\n",
      "  Downloading deep_translator-1.10.0-py3-none-any.whl (35 kB)\n",
      "Collecting requests<3.0.0,>=2.23.0\n",
      "  Downloading requests-2.28.2-py3-none-any.whl (62 kB)\n",
      "     ---------------------------------------- 62.8/62.8 kB 3.5 MB/s eta 0:00:00\n",
      "Collecting docx2txt[docx]<0.9,>=0.8\n",
      "  Downloading docx2txt-0.8.tar.gz (2.8 kB)\n",
      "  Preparing metadata (setup.py): started\n",
      "  Preparing metadata (setup.py): finished with status 'done'\n",
      "Collecting beautifulsoup4<5.0.0,>=4.9.1\n",
      "  Downloading beautifulsoup4-4.11.2-py3-none-any.whl (129 kB)\n",
      "     -------------------------------------- 129.4/129.4 kB 3.8 MB/s eta 0:00:00\n",
      "Collecting pypdf[pdf]<4.0.0,>=3.3.0\n",
      "  Downloading pypdf-3.4.0-py3-none-any.whl (241 kB)\n",
      "     -------------------------------------- 241.5/241.5 kB 4.9 MB/s eta 0:00:00\n",
      "Collecting soupsieve>1.2\n",
      "  Downloading soupsieve-2.3.2.post1-py3-none-any.whl (37 kB)\n",
      "Requirement already satisfied: idna<4,>=2.5 in c:\\users\\dhana\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.10_qbz5n2kfra8p0\\localcache\\local-packages\\python310\\site-packages (from requests<3.0.0,>=2.23.0->deep-translator) (2.10)\n",
      "Collecting charset-normalizer<4,>=2\n",
      "  Downloading charset_normalizer-3.0.1-cp310-cp310-win_amd64.whl (96 kB)\n",
      "     ---------------------------------------- 96.5/96.5 kB 5.4 MB/s eta 0:00:00\n",
      "Requirement already satisfied: certifi>=2017.4.17 in c:\\users\\dhana\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.10_qbz5n2kfra8p0\\localcache\\local-packages\\python310\\site-packages (from requests<3.0.0,>=2.23.0->deep-translator) (2022.12.7)\n",
      "Collecting urllib3<1.27,>=1.21.1\n",
      "  Downloading urllib3-1.26.14-py2.py3-none-any.whl (140 kB)\n",
      "     -------------------------------------- 140.6/140.6 kB 8.2 MB/s eta 0:00:00\n",
      "Installing collected packages: docx2txt, charset-normalizer, urllib3, soupsieve, pypdf, requests, beautifulsoup4, deep-translator\n",
      "  Running setup.py install for docx2txt: started\n",
      "  Running setup.py install for docx2txt: finished with status 'done'\n",
      "Successfully installed beautifulsoup4-4.11.2 charset-normalizer-3.0.1 deep-translator-1.10.0 docx2txt-0.8 pypdf-3.4.0 requests-2.28.2 soupsieve-2.3.2.post1 urllib3-1.26.14\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING: Ignoring invalid distribution -ip (c:\\users\\dhana\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.10_qbz5n2kfra8p0\\localcache\\local-packages\\python310\\site-packages)\n",
      "WARNING: Ignoring invalid distribution -ip (c:\\users\\dhana\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.10_qbz5n2kfra8p0\\localcache\\local-packages\\python310\\site-packages)\n",
      "WARNING: docx2txt 0.8 does not provide the extra 'docx'\n",
      "WARNING: pypdf 3.4.0 does not provide the extra 'pdf'\n",
      "WARNING: Ignoring invalid distribution -ip (c:\\users\\dhana\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.10_qbz5n2kfra8p0\\localcache\\local-packages\\python310\\site-packages)\n",
      "  DEPRECATION: docx2txt is being installed using the legacy 'setup.py install' method, because it does not have a 'pyproject.toml' and the 'wheel' package is not installed. pip 23.1 will enforce this behaviour change. A possible replacement is to enable the '--use-pep517' option. Discussion can be found at https://github.com/pypa/pip/issues/8559\n",
      "  WARNING: The script normalizer.exe is installed in 'C:\\Users\\dhana\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.10_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python310\\Scripts' which is not on PATH.\n",
      "  Consider adding this directory to PATH or, if you prefer to suppress this warning, use --no-warn-script-location.\n",
      "  WARNING: The scripts deep-translator.exe and dt.exe are installed in 'C:\\Users\\dhana\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.10_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python310\\Scripts' which is not on PATH.\n",
      "  Consider adding this directory to PATH or, if you prefer to suppress this warning, use --no-warn-script-location.\n",
      "WARNING: Ignoring invalid distribution -ip (c:\\users\\dhana\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.10_qbz5n2kfra8p0\\localcache\\local-packages\\python310\\site-packages)\n",
      "WARNING: Ignoring invalid distribution -ip (c:\\users\\dhana\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.10_qbz5n2kfra8p0\\localcache\\local-packages\\python310\\site-packages)\n",
      "WARNING: Ignoring invalid distribution -ip (c:\\users\\dhana\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.10_qbz5n2kfra8p0\\localcache\\local-packages\\python310\\site-packages)\n",
      "WARNING: Ignoring invalid distribution -ip (c:\\users\\dhana\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.10_qbz5n2kfra8p0\\localcache\\local-packages\\python310\\site-packages)\n",
      "WARNING: Ignoring invalid distribution -ip (c:\\users\\dhana\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.10_qbz5n2kfra8p0\\localcache\\local-packages\\python310\\site-packages)\n",
      "WARNING: Ignoring invalid distribution -ip (c:\\users\\dhana\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.10_qbz5n2kfra8p0\\localcache\\local-packages\\python310\\site-packages)\n",
      "WARNING: Ignoring invalid distribution -ip (c:\\users\\dhana\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.10_qbz5n2kfra8p0\\localcache\\local-packages\\python310\\site-packages)\n",
      "WARNING: Ignoring invalid distribution -ip (c:\\users\\dhana\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.10_qbz5n2kfra8p0\\localcache\\local-packages\\python310\\site-packages)\n",
      "WARNING: Ignoring invalid distribution -ip (c:\\users\\dhana\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.10_qbz5n2kfra8p0\\localcache\\local-packages\\python310\\site-packages)\n",
      "WARNING: Ignoring invalid distribution -ip (c:\\users\\dhana\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.10_qbz5n2kfra8p0\\localcache\\local-packages\\python310\\site-packages)\n",
      "WARNING: Ignoring invalid distribution -ip (c:\\users\\dhana\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.10_qbz5n2kfra8p0\\localcache\\local-packages\\python310\\site-packages)\n"
     ]
    }
   ],
   "source": [
    "pip install deep-translator"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Installing NLTK\n",
    "#pip install --user -U nltk"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting nltk\n",
      "  Downloading nltk-3.8.1-py3-none-any.whl (1.5 MB)\n",
      "     ---------------------------------------- 1.5/1.5 MB 3.4 MB/s eta 0:00:00\n",
      "Collecting tqdm\n",
      "  Downloading tqdm-4.64.1-py2.py3-none-any.whl (78 kB)\n",
      "     ---------------------------------------- 78.5/78.5 kB 4.5 MB/s eta 0:00:00\n",
      "Collecting click\n",
      "  Downloading click-8.1.3-py3-none-any.whl (96 kB)\n",
      "     ---------------------------------------- 96.6/96.6 kB 5.4 MB/s eta 0:00:00\n",
      "Collecting regex>=2021.8.3\n",
      "  Downloading regex-2022.10.31-cp310-cp310-win_amd64.whl (267 kB)\n",
      "     -------------------------------------- 267.7/267.7 kB 5.6 MB/s eta 0:00:00\n",
      "Requirement already satisfied: joblib in c:\\users\\dhana\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.10_qbz5n2kfra8p0\\localcache\\local-packages\\python310\\site-packages (from nltk) (1.2.0)\n",
      "Requirement already satisfied: colorama in c:\\users\\dhana\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.10_qbz5n2kfra8p0\\localcache\\local-packages\\python310\\site-packages (from click->nltk) (0.4.6)\n",
      "Installing collected packages: tqdm, regex, click, nltk\n",
      "Successfully installed click-8.1.3 nltk-3.8.1 regex-2022.10.31 tqdm-4.64.1\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING: Ignoring invalid distribution -ip (c:\\users\\dhana\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.10_qbz5n2kfra8p0\\localcache\\local-packages\\python310\\site-packages)\n",
      "WARNING: Ignoring invalid distribution -ip (c:\\users\\dhana\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.10_qbz5n2kfra8p0\\localcache\\local-packages\\python310\\site-packages)\n",
      "WARNING: Ignoring invalid distribution -ip (c:\\users\\dhana\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.10_qbz5n2kfra8p0\\localcache\\local-packages\\python310\\site-packages)\n",
      "  WARNING: The script tqdm.exe is installed in 'C:\\Users\\dhana\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.10_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python310\\Scripts' which is not on PATH.\n",
      "  Consider adding this directory to PATH or, if you prefer to suppress this warning, use --no-warn-script-location.\n",
      "  WARNING: The script nltk.exe is installed in 'C:\\Users\\dhana\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.10_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python310\\Scripts' which is not on PATH.\n",
      "  Consider adding this directory to PATH or, if you prefer to suppress this warning, use --no-warn-script-location.\n",
      "WARNING: Ignoring invalid distribution -ip (c:\\users\\dhana\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.10_qbz5n2kfra8p0\\localcache\\local-packages\\python310\\site-packages)\n",
      "WARNING: Ignoring invalid distribution -ip (c:\\users\\dhana\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.10_qbz5n2kfra8p0\\localcache\\local-packages\\python310\\site-packages)\n",
      "WARNING: Ignoring invalid distribution -ip (c:\\users\\dhana\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.10_qbz5n2kfra8p0\\localcache\\local-packages\\python310\\site-packages)\n",
      "WARNING: Ignoring invalid distribution -ip (c:\\users\\dhana\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.10_qbz5n2kfra8p0\\localcache\\local-packages\\python310\\site-packages)\n",
      "WARNING: Ignoring invalid distribution -ip (c:\\users\\dhana\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.10_qbz5n2kfra8p0\\localcache\\local-packages\\python310\\site-packages)\n",
      "WARNING: Ignoring invalid distribution -ip (c:\\users\\dhana\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.10_qbz5n2kfra8p0\\localcache\\local-packages\\python310\\site-packages)\n",
      "WARNING: Ignoring invalid distribution -ip (c:\\users\\dhana\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.10_qbz5n2kfra8p0\\localcache\\local-packages\\python310\\site-packages)\n"
     ]
    }
   ],
   "source": [
    "pip install --user -U nltk"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Importing all the import packages/lib "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Error loading punkt: <urlopen error [WinError 10060] A\n",
      "[nltk_data]     connection attempt failed because the connected party\n",
      "[nltk_data]     did not properly respond after a period of time, or\n",
      "[nltk_data]     established connection failed because connected host\n",
      "[nltk_data]     has failed to respond>\n",
      "[nltk_data] Error loading wordnet: <urlopen error [WinError 10060] A\n",
      "[nltk_data]     connection attempt failed because the connected party\n",
      "[nltk_data]     did not properly respond after a period of time, or\n",
      "[nltk_data]     established connection failed because connected host\n",
      "[nltk_data]     has failed to respond>\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import nltk\n",
    "nltk.download(\"punkt\")\n",
    "nltk.download(\"wordnet\")\n",
    "from deep_translator import GoogleTranslator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>English words/sentences</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Hi.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Run!</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Run!</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Who?</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Wow!</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  English words/sentences\n",
       "0                     Hi.\n",
       "1                    Run!\n",
       "2                    Run!\n",
       "3                    Who?\n",
       "4                    Wow!"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#importing the dataset\n",
    "data = pd.read_csv(\"English.csv\")\n",
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                                            English Words\n",
      "0                                                     Hi.\n",
      "1                                                    Run!\n",
      "2                                                    Who?\n",
      "3                                                    Wow!\n",
      "4                                                   Fire!\n",
      "...                                                   ...\n",
      "123095  Top-down economics never works, said Obama. \"T...\n",
      "123096  A carbon footprint is the amount of carbon dio...\n",
      "123097  Death is something that we're often discourage...\n",
      "123098  Since there are usually multiple websites on a...\n",
      "123099  If someone who doesn't know your background sa...\n",
      "\n",
      "[123100 rows x 1 columns]\n"
     ]
    }
   ],
   "source": [
    "Trans_En = pd.DataFrame(data[\"English words/sentences\"].unique()).rename(columns = {0:'English Words'})\n",
    "print(Trans_En)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\dhana\\AppData\\Local\\Temp\\ipykernel_15144\\3701053760.py:1: FutureWarning: The default value of regex will change from True to False in a future version.\n",
      "  Trans_En[\"English Words\"] = Trans_En[\"English Words\"].str.replace(\"[^a-zA-Z0-9]\", \" \")\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0          Hi \n",
       "1         Run \n",
       "2         Who \n",
       "3         Wow \n",
       "4        Fire \n",
       "        ...   \n",
       "95    Open up \n",
       "96    Perfect \n",
       "97    See you \n",
       "98    See you \n",
       "99    Show me \n",
       "Name: English Words, Length: 100, dtype: object"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Trans_En[\"English Words\"] = Trans_En[\"English Words\"].str.replace(\"[^a-zA-Z0-9]\", \" \") \n",
    "Trans_En[\"English Words\"].head(100)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Creating the function to Traslate English words to Spanish/Espaniol."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def Translate_Es(s1):\n",
    "    translation_tokenized=GoogleTranslator(source='english', target='es').translate(s1)\n",
    "    return translation_tokenized"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Displaying 100 words/sentences translated to Spanish/Espaniol from English"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Hola',\n",
       " 'Correr',\n",
       " 'OMS',\n",
       " 'Guau',\n",
       " 'Fuego',\n",
       " 'Ayuda',\n",
       " 'Saltar',\n",
       " 'Detener',\n",
       " 'Esperar',\n",
       " 'Seguir',\n",
       " 'Hola',\n",
       " 'Veo',\n",
       " 'lo intento',\n",
       " 'gané',\n",
       " 'gané',\n",
       " 'Oh, no',\n",
       " 'Ataque',\n",
       " 'Salud',\n",
       " 'Levantarse',\n",
       " 'Ve ahora',\n",
       " 'Entiendo',\n",
       " 'Entiendo',\n",
       " 'súbete',\n",
       " 'Abrázame',\n",
       " 'Me caí',\n",
       " 'Sé',\n",
       " 'me fui',\n",
       " 'mentí',\n",
       " 'perdí',\n",
       " 'He pagado',\n",
       " 'Tengo 19',\n",
       " 'Estoy bien',\n",
       " 'Escuchar',\n",
       " 'De ninguna manera',\n",
       " 'En realidad',\n",
       " 'Gracias',\n",
       " 'Intentamos',\n",
       " 'Ganamos',\n",
       " 'preguntale a tom',\n",
       " 'Impresionante',\n",
       " 'Estate calmado',\n",
       " 'Relájate',\n",
       " 'Sé justo',\n",
       " 'Sé amable',\n",
       " 'Se bueno',\n",
       " 'Batirlo',\n",
       " 'Llámame',\n",
       " 'Llámanos',\n",
       " 'Adelante',\n",
       " 'Vamos',\n",
       " 'Vamos',\n",
       " 'Déjalo caer',\n",
       " 'conseguir tom',\n",
       " 'Salir',\n",
       " 'Salir',\n",
       " 'Irse',\n",
       " 'Irse',\n",
       " 'Vete a casa',\n",
       " 'Ve lento',\n",
       " 'Adiós',\n",
       " 'Aférrate',\n",
       " 'Aférrate',\n",
       " 'El lo dejó',\n",
       " 'El corre',\n",
       " 'Ayúdame',\n",
       " 'Ayúdame',\n",
       " 'Ayúdanos',\n",
       " 'aguantalo',\n",
       " 'Esperar',\n",
       " 'abrazo tom',\n",
       " 'Estoy de acuerdo',\n",
       " 'lloré',\n",
       " 'yo dormitaba',\n",
       " 'conduzco',\n",
       " 'yo fumo',\n",
       " 'yo ronco',\n",
       " 'Apesto',\n",
       " 'Me paré',\n",
       " 'lo jure',\n",
       " 'Lo intenté',\n",
       " 'Saludé',\n",
       " 'Iré',\n",
       " 'Soy Tom',\n",
       " 'Estoy gordo',\n",
       " 'Estoy en forma',\n",
       " 'Estoy golpeado',\n",
       " 'Estoy enfermo',\n",
       " 'Estoy triste',\n",
       " 'Soy tímido',\n",
       " 'Estoy mojado',\n",
       " 'Soy yo',\n",
       " 'Únete a nosotros',\n",
       " 'Quédatelo',\n",
       " 'Bésame',\n",
       " 'Yo también',\n",
       " 'Abrir',\n",
       " 'Perfecto',\n",
       " 'Nos vemos',\n",
       " 'Nos vemos',\n",
       " 'Muéstrame']"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Trans_Spanish_Words = [Translate_Es(r) for r in Trans_En[\"English Words\"].head(100)]\n",
    "Trans_Spanish_Words"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Creating the function to Traslate English words to French"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "def Translate_Fr(s1):\n",
    "    translation_tokenized = GoogleTranslator(source='english', target='fr').translate(s1)\n",
    "    return translation_tokenized"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Displaying 100 words/sentences translated to French from English"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Salut',\n",
       " 'Courir',\n",
       " 'OMS',\n",
       " 'Ouah',\n",
       " 'Feu',\n",
       " 'Aider',\n",
       " 'Saut',\n",
       " 'Arrêt',\n",
       " 'Attendez',\n",
       " 'Continue',\n",
       " 'Bonjour',\n",
       " 'Je vois',\n",
       " \"J'essaye\",\n",
       " \"J'ai gagné\",\n",
       " \"J'ai gagné\",\n",
       " 'Oh non',\n",
       " 'Attaque',\n",
       " 'Acclamations',\n",
       " 'Se lever',\n",
       " 'Allez maintenant',\n",
       " \"J'ai compris\",\n",
       " \"J'ai compris\",\n",
       " 'Monter dedans',\n",
       " 'HUG Me',\n",
       " 'je suis tombé',\n",
       " 'Je sais',\n",
       " 'Je suis parti',\n",
       " \"j'ai menti\",\n",
       " \"J'ai perdu\",\n",
       " \"j'ai payé\",\n",
       " \"J'ai 19 ans\",\n",
       " 'Je vais bien',\n",
       " 'Écouter',\n",
       " 'Certainement pas',\n",
       " 'Vraiment',\n",
       " 'Merci',\n",
       " 'Nous essayons',\n",
       " 'Nous avons gagné',\n",
       " 'Demander à Tom',\n",
       " 'Génial',\n",
       " 'Sois calme',\n",
       " 'Soit cool',\n",
       " 'Être juste',\n",
       " 'Etre gentil',\n",
       " 'Sois gentil',\n",
       " 'Batte-le',\n",
       " 'Appelez-moi',\n",
       " 'Appelez-nous',\n",
       " 'Entrez',\n",
       " 'Allez',\n",
       " 'Allez',\n",
       " 'Laisse tomber',\n",
       " 'Obtenez Tom',\n",
       " 'Sortir',\n",
       " 'Sortir',\n",
       " \"S'en aller\",\n",
       " \"S'en aller\",\n",
       " 'rentrer chez soi',\n",
       " 'Va lentement',\n",
       " 'Au revoir',\n",
       " 'Attendez',\n",
       " 'Attendez',\n",
       " 'Il quitte',\n",
       " 'Il court',\n",
       " 'Aide-moi',\n",
       " 'Aide-moi',\n",
       " 'Aidez nous',\n",
       " 'Le tenir',\n",
       " 'Attendez',\n",
       " 'Câlin à Tom',\n",
       " \"Je suis d'accord\",\n",
       " \"J'ai pleuré\",\n",
       " 'je me suis assoupi',\n",
       " 'je conduis',\n",
       " 'je fume',\n",
       " 'je ronfle',\n",
       " 'je pue',\n",
       " 'je me tenais',\n",
       " \"j'ai juré\",\n",
       " \"J'ai essayé\",\n",
       " \"j'ai agité\",\n",
       " \"J'y vais\",\n",
       " 'Je suis Tom',\n",
       " 'Je suis gros',\n",
       " 'Je suis mince',\n",
       " 'Je suis touché',\n",
       " 'Je suis malade',\n",
       " 'Je suis triste',\n",
       " 'Je suis timide',\n",
       " 'Je suis trempé',\n",
       " \"C'est moi\",\n",
       " 'Rejoignez-nous',\n",
       " 'Garde le',\n",
       " 'Embrasse-moi',\n",
       " 'Moi aussi',\n",
       " \"S'ouvrir\",\n",
       " 'Parfait',\n",
       " 'À bientôt',\n",
       " 'À bientôt',\n",
       " 'Montre-moi']"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Trans_French_Words = [Translate_Fr(r) for r in Trans_En[\"English Words\"].head(100)]\n",
    "Trans_French_Words"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Creating the function to Traslate English words to German/Deutsch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "def Translate_deu(s1):\n",
    "    translation_tokenized=GoogleTranslator(source='english', target='de').translate(s1)\n",
    "    return translation_tokenized"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Displaying 100 words/sentences translated to Deutsch from English"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Hallo',\n",
       " 'Laufen',\n",
       " 'WHO',\n",
       " 'Wow',\n",
       " 'Feuer',\n",
       " 'Hilfe',\n",
       " 'Springen',\n",
       " 'Stoppen',\n",
       " 'Warten',\n",
       " 'Mach weiter',\n",
       " 'Hallo',\n",
       " 'Ich verstehe',\n",
       " 'ich versuche',\n",
       " 'ich habe gewonnen',\n",
       " 'ich habe gewonnen',\n",
       " 'Ach nein',\n",
       " 'Attacke',\n",
       " 'Beifall',\n",
       " 'Aufstehen',\n",
       " 'Geh jetzt',\n",
       " 'Habe es',\n",
       " 'Habe es',\n",
       " 'Steigen Sie ein',\n",
       " 'Umarme mich',\n",
       " 'Ich fiel',\n",
       " 'Ich weiss',\n",
       " 'Ich ging weg',\n",
       " 'ich habe gelogen',\n",
       " 'Ich habe verloren',\n",
       " 'ich habe bezahlt',\n",
       " 'Ich bin 19',\n",
       " 'Ich bin ok',\n",
       " 'Hören',\n",
       " 'Auf keinen Fall',\n",
       " 'Wirklich',\n",
       " 'Danke',\n",
       " 'Wir versuchen',\n",
       " 'Wir haben gewonnen',\n",
       " 'Frag Tom',\n",
       " 'Eindrucksvoll',\n",
       " 'Ruhig sein',\n",
       " 'Sei cool',\n",
       " 'Sei fair',\n",
       " 'Freundlich sein',\n",
       " 'Sei nett',\n",
       " 'Mach dich vom Acker',\n",
       " 'Rufen Sie mich an',\n",
       " 'Rufen Sie uns an',\n",
       " 'Komm herein',\n",
       " 'Aufleuchten',\n",
       " 'Aufleuchten',\n",
       " 'Lass es fallen',\n",
       " 'Hol Tom',\n",
       " 'Aussteigen',\n",
       " 'Aussteigen',\n",
       " 'Geh weg',\n",
       " 'Geh weg',\n",
       " 'Nach Hause gehen',\n",
       " 'Mach langsam',\n",
       " 'Auf Wiedersehen',\n",
       " 'Abwarten',\n",
       " 'Abwarten',\n",
       " 'Er hat gekündigt',\n",
       " 'Er rennt',\n",
       " 'Hilf mir',\n",
       " 'Hilf mir',\n",
       " 'Hilf uns',\n",
       " 'Halte es',\n",
       " 'Festhalten',\n",
       " 'Umarmung Tom',\n",
       " 'Ich stimme zu',\n",
       " 'Ich weinte',\n",
       " 'Ich döste',\n",
       " 'ich fahre',\n",
       " 'ich rauche',\n",
       " 'ich schnarche',\n",
       " 'ich stinke',\n",
       " 'ich stand',\n",
       " 'Ich schwor',\n",
       " 'Ich habe es versucht',\n",
       " 'ich winkte',\n",
       " 'Ich werde gehen',\n",
       " 'Ich bin Tom',\n",
       " 'Ich bin fett',\n",
       " 'Ich bin Fit',\n",
       " 'Ich bin getroffen',\n",
       " 'Ich bin krank',\n",
       " 'Ich bin traurig',\n",
       " 'Ich bin schüchtern',\n",
       " 'Ich bin nass',\n",
       " 'Da ich bin',\n",
       " 'Begleiten Sie uns',\n",
       " 'Behalte es',\n",
       " 'Küss mich',\n",
       " 'Ich auch',\n",
       " 'Aufmachen',\n",
       " 'Perfekt',\n",
       " \"Mach's gut\",\n",
       " \"Mach's gut\",\n",
       " 'Zeig mir']"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Trans_German_Words = [Translate_deu(r) for r in Trans_En[\"English Words\"].head(100)]\n",
    "Trans_German_Words"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.10"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "78205b1b5f87c79fbdc796b1d90a9b4c2b4e460cd0193ed573d48cc3cc88d394"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
